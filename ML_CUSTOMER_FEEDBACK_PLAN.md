# Machine Learning Customer Feedback Classification Plan

## üéØ Projektziel

Entwicklung eines ML-Systems zur automatischen Klassifizierung von Kundenfeedback aus Telefongespr√§chen, um:
1. Kundenzufriedenheit zu bewerten (positiv/negativ)
2. Zielerreichung zu erkennen (Termin gebucht, Informationen erhalten, etc.)
3. Gespr√§che automatisch zu kategorisieren
4. Performance des AI-Agenten zu messen

## üìä Verf√ºgbare Daten

### Aus der Call-Tabelle:
- **transcript**: Vollst√§ndiges Transkript des Gespr√§chs
- **audio_url**: URL zur Audiodatei
- **sentiment**: Bereits erfasste Stimmung (falls vorhanden)
- **sentiment_score**: Numerischer Sentiment-Wert
- **analysis**: JSON-Feld mit zus√§tzlichen Analysen
- **call_successful**: Boolean f√ºr erfolgreichen Anruf
- **duration_sec**: Anrufdauer
- **appointment_id**: Verkn√ºpfung zu gebuchtem Termin (falls vorhanden)

### Zus√§tzliche Kontextdaten:
- **customer_id**: F√ºr Kundenhistorie
- **agent_id**: F√ºr Agent-Performance
- **company_id/branch_id**: F√ºr gesch√§ftsspezifische Ziele

## üîÑ Workflow

### Phase 1: Plan ‚úì
1. Analysiere vorhandene Datenstruktur
2. Definiere Klassifizierungsziele
3. Erstelle Projektplan

### Phase 2: Specification
1. Detaillierte technische Spezifikation
2. Feature-Engineering-Pipeline
3. Modell-Architektur
4. Evaluationsmetriken

### Phase 3: Test (Pre-Implementation)
1. Datenqualit√§ts-Check
2. Baseline-Performance ohne ML
3. Test-Datensatz erstellen

### Phase 4: Build
1. Datenaufbereitung
2. Feature-Extraktion
3. Modell-Training
4. API-Integration

### Phase 5: Test (Post-Implementation)
1. Modell-Evaluation
2. A/B-Testing
3. Performance-Monitoring

## üéØ Klassifizierungsziele

### 1. Sentiment-Analyse (Binary + Multi-class)
- **Positiv**: Zufriedener Kunde, freundlich, dankbar
- **Neutral**: Sachlich, ohne emotionale F√§rbung
- **Negativ**: Unzufrieden, frustriert, ver√§rgert

### 2. Zielerreichung (Multi-label)
- **appointment_booked**: Termin erfolgreich gebucht
- **information_received**: Kunde hat gew√ºnschte Info erhalten
- **callback_scheduled**: R√ºckruf vereinbart
- **transferred_to_human**: An Mitarbeiter weitergeleitet
- **issue_resolved**: Problem gel√∂st
- **no_action_needed**: Keine Aktion erforderlich

### 3. Gespr√§chsqualit√§t
- **clarity_score**: Klarheit der Kommunikation (0-1)
- **efficiency_score**: Effizienz der Zielerreichung (0-1)
- **professionalism_score**: Professionalit√§t des Agenten (0-1)

### 4. Business-Metriken
- **conversion_probability**: Wahrscheinlichkeit einer Buchung
- **customer_lifetime_value_impact**: Einfluss auf Kundenwert
- **urgency_level**: Dringlichkeit (low/medium/high)

## üõ†Ô∏è Technologie-Stack

### Core ML Libraries
- **scikit-learn**: Hauptframework f√ºr ML-Modelle
- **pandas**: Datenverarbeitung
- **numpy**: Numerische Berechnungen
- **nltk/spacy**: NLP f√ºr Deutsch

### Feature Engineering
- **librosa**: Audio-Feature-Extraktion (falls Audio verwendet)
- **transformers**: Pre-trained Language Models (BERT f√ºr Deutsch)
- **textblob-de**: Deutsche Sentiment-Analyse

### Integration
- **Laravel Jobs**: Asynchrone Verarbeitung
- **Redis**: Feature-Caching
- **PostgreSQL**: ML-Modell-Versionierung

## üìà Features f√ºr das Modell

### Text-basierte Features (aus Transkript)
1. **Basis-Features**:
   - Wortanzahl
   - Satzanzahl
   - Durchschnittliche Satzl√§nge
   - Anzahl Fragezeichen
   - Anzahl Ausrufezeichen

2. **NLP-Features**:
   - TF-IDF Vektoren (Top 1000 W√∂rter)
   - N-Gramme (Unigrams, Bigrams)
   - Part-of-Speech Tags
   - Named Entity Recognition (Datum, Zeit, Namen)

3. **Sentiment-Features**:
   - Polarit√§t pro Satz
   - Subjektivit√§t
   - Emotionale W√∂rter (positiv/negativ)
   - H√∂flichkeitsmarker

4. **Konversations-Features**:
   - Anzahl Sprecherwechsel
   - Verh√§ltnis Agent zu Kunde Sprechzeit
   - L√§ngste Pause
   - Anzahl Unterbrechungen

### Audio-basierte Features (optional)
1. **Prosodische Features**:
   - Pitch (Tonh√∂he)
   - Energy (Lautst√§rke)
   - Speaking Rate
   - Voice Activity Detection

2. **Emotionale Features**:
   - Stress-Level
   - Arousal
   - Valence

### Kontext-Features
1. **Zeitliche Features**:
   - Tageszeit
   - Wochentag
   - Monat
   - Feiertag (ja/nein)

2. **Kunden-Features**:
   - Neue vs. Bestandskunde
   - Anzahl vorheriger Anrufe
   - Historie der Zufriedenheit

3. **Business-Features**:
   - Service-Typ
   - Filiale
   - Agent-Version

## üéØ Modell-Architektur

### Ensemble-Ansatz
1. **Text-Klassifikator** (Random Forest)
   - Input: TF-IDF + NLP Features
   - Output: Sentiment, Zielerreichung

2. **Audio-Klassifikator** (Optional, SVM)
   - Input: Audio-Features
   - Output: Emotionaler Zustand

3. **Meta-Klassifikator** (Gradient Boosting)
   - Input: Outputs der Sub-Modelle + Kontext
   - Output: Finale Klassifizierung

## üìä Evaluationsmetriken

### Prim√§re Metriken
- **Accuracy**: Gesamtgenauigkeit
- **F1-Score**: Balance zwischen Precision und Recall
- **AUC-ROC**: F√ºr bin√§re Klassifikationen

### Business-Metriken
- **False Negative Rate**: Verpasste unzufriedene Kunden
- **Conversion Accuracy**: Korrekte Vorhersage von Buchungen
- **Alert Precision**: Genauigkeit bei kritischen F√§llen

## üöÄ Implementierungsschritte

### Woche 1: Datenvorbereitung
- [ ] Daten aus DB extrahieren
- [ ] Transkripte bereinigen
- [ ] Labels manuell annotieren (Sample)

### Woche 2: Feature Engineering
- [ ] Text-Feature-Pipeline
- [ ] Audio-Feature-Pipeline (optional)
- [ ] Feature-Selection

### Woche 3: Modell-Training
- [ ] Baseline-Modelle
- [ ] Hyperparameter-Tuning
- [ ] Ensemble-Building

### Woche 4: Integration & Testing
- [ ] API-Endpoints
- [ ] Batch-Processing Jobs
- [ ] Performance-Tests

## üé® Deliverables

1. **ML-Pipeline**: Vollst√§ndige Feature-Engineering und Training Pipeline
2. **API-Endpoints**: REST-API f√ºr Echtzeit-Klassifizierung
3. **Dashboard**: Visualisierung der Ergebnisse
4. **Dokumentation**: Technische Docs und Benutzerhandbuch
5. **Monitoring**: Alerting-System f√ºr schlechte Gespr√§che

## ‚ö†Ô∏è Risiken & Mitigationen

1. **Datenschutz**: 
   - Anonymisierung pers√∂nlicher Daten
   - On-Premise Deployment Option

2. **Bias im Modell**:
   - Regelm√§√üige Bias-Audits
   - Diverse Trainingsdaten

3. **Performance**:
   - Caching von Features
   - Asynchrone Verarbeitung

4. **Sprachvielfalt**:
   - Dialekte und Akzente ber√ºcksichtigen
   - Continuous Learning Pipeline

## üìÖ Timeline

- **Woche 1-2**: Specification & Test Planning
- **Woche 3-4**: Implementation
- **Woche 5**: Testing & Evaluation
- **Woche 6**: Deployment & Monitoring

---

**N√§chster Schritt**: Technische Spezifikation erstellen mit detaillierten Implementierungsdetails.